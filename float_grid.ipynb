{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data Processing for 3PG Dataset\n",
    "\n",
    "This script processes climate data for the 3PG dataset. It involves extracting, converting, and reformatting raster data using arcpy and regular expressions. The processed data is then saved in specified output folders and text files. The script can be divided into the following sections:\n",
    "\n",
    "1. **Importing Packages and Setting Up Environment**:\n",
    "   - Import required packages including arcpy, os, re, and time.\n",
    "   - Check out the \"Spatial\" extension for arcpy.\n",
    "   - Define the workspace for input and output files.\n",
    "   - Enable overwrite output to allow file overwriting during processing.\n",
    "\n",
    "2. **Folder and Time Period Configuration**:\n",
    "   - Define the list of folders containing input data (e.g., \"Switzerland_pr\", \"Switzerland_tasmax\").\n",
    "   - Specify the start and last years for data processing.\n",
    "\n",
    "3. **Data Elaboration - Extraction, Conversion, and Projection**:\n",
    "   - Iterate through each folder and process data for each file.\n",
    "   - Extract the year and month from filenames using regular expressions.\n",
    "   - Convert raster files to floating-point format using `RasterToFloat`.\n",
    "   - Define the projection for the processed data using `DefineProjection`. The data are projected to the CH1903+ LV95 coordinate system.\n",
    "   - Save processed data in the corresponding output folder.\n",
    "\n",
    "4. **Output and Progress**:\n",
    "   - Print progress and information for each processed file.\n",
    "\n",
    "5. **File Organization and Text File Creation**:\n",
    "   - Group processed files by year.\n",
    "   - Write the file paths and years to a text file for each folder.\n",
    "\n",
    "6. **Removing NODATA Header Lines**:\n",
    "   - Iterate through each folder and remove NODATA header lines from .hdr files.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **ArcGIS Software**: This script requires arcpy, which is part of the ArcGIS software suite. Ensure you have a compatible version of ArcGIS installed.\n",
    "\n",
    "2. **Input Data**: Prepare the input raster data and ensure it's located in the specified folders.\n",
    "\n",
    "3. **Configuration**: Modify the script's parameters, such as workspace paths, time periods, and file extensions to match your dataset and requirements.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. **Open the Jupyter Notebook**: Launch your Jupyter Notebook environment. Modify the script's parameters to match your setup.\n",
    "\n",
    "2. **Run the Notebook Cells**: Execute the notebook cells sequentially by clicking on each cell and pressing Shift + Enter. Make sure to run the cells in the correct order.\n",
    "\n",
    "2. **Output**: Processed climate data files will be saved in the specified output folders. Text files containing lists of processed files grouped by year will also be created.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Verify the correctness and accuracy of the processed data after running the script.\n",
    "- Review the regular expressions and processing steps to ensure they match the filename patterns and data structure.\n",
    "- Check the projection details and coordinate system parameters in the `DefineProjection` function for proper assignment.\n",
    "- Ensure compliance with data usage agreements and copyrights when processing external datasets.\n",
    "\n",
    "## Author\n",
    "\n",
    "Script written by Luca Ferrari\n",
    "\n",
    "Contact: luca.ferrari@usys.ethz.ch\n",
    "\n",
    "For inquiries or assistance, please contact the author.\n",
    "\n",
    "This README content was generated with the assistance of an AI language model from OpenAI. The provided content is based on user input and has been tailored to the specific requirements of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import packages\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "arcpy.CheckOutExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define workspace\n",
    "env.workspace = r\"N:\\Luca_data\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "folders = [\"Switzerland_pr\", \"Switzerland_tasmax\", \"Switzerland_tasmin\", \"Switzerland_fst\", \"Switzerland_rsds\", \"Switzerland_vpd\"]\n",
    "\n",
    "start_year = 1980\n",
    "last_year = 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(env.workspace, \"Chelsa_V2_Monthly\\Resampled data 250m\", folder)\n",
    "\n",
    "    output_path = os.path.join(env.workspace, \"3PG\", folder)\n",
    "\n",
    "    # Create output folder if it does not exist\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # Get the list of files in the directory using os.scandir()\n",
    "    with os.scandir(folder_path) as entries:\n",
    "        # Filter out directories and get only file names\n",
    "        file_names = [entry.name for entry in entries if entry.is_file()]\n",
    "        # Filter the list to only include .tif files\n",
    "        file_names = [f for f in file_names if f.endswith('.tif')]\n",
    "\n",
    "    # Define the regular expression pattern to extract the date from the filename\n",
    "    pattern = r'\\d{4}'\n",
    "\n",
    "    # Iterate over the files in the directory\n",
    "    for file_name in file_names:\n",
    "        # Extract the date from the filename using the regular expression pattern\n",
    "        match = re.search(pattern, file_name)\n",
    "        if match:\n",
    "            # Extract the year from the matched date\n",
    "            year = int(match.group(0))\n",
    "            \n",
    "            # Check if the year is between 2013 and 2018\n",
    "            if start_year <= year <= last_year:\n",
    "                # Create the full path to the file\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                month_match = re.search(r\"_(\\d{2})\\_\", file_name)\n",
    "                month = int(month_match.group(1))\n",
    "\n",
    "                #output_file_path =  os.path.join(output_path, f\"{extracted_word}_{month}_{year}.flt\")\n",
    "                match = re.search(r\"(_\\w+)\", folder)\n",
    "                extracted_word2 = match.group(1)\n",
    "                y = \"Y\"\n",
    "                output_file_path =  os.path.join(output_path, f\"{y.upper()}{year}{extracted_word2}_{str(month).zfill(2)}.flt\")\n",
    "                    \n",
    "                arcpy.conversion.RasterToFloat(\n",
    "                    in_raster = file_path,\n",
    "                    out_float_file = output_file_path\n",
    "                )\n",
    "\n",
    "                # Add a delay of 5 second before defining the projection\n",
    "                time.sleep(2)\n",
    "\n",
    "                arcpy.management.DefineProjection(\n",
    "                    in_dataset=output_file_path,\n",
    "                    coor_system='PROJCS[\"CH1903+_LV95\",GEOGCS[\"GCS_CH1903+\",DATUM[\"D_CH1903+\",SPHEROID[\"Bessel_1841\",6377397.155,299.1528128]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"False_Easting\",2600000.0],PARAMETER[\"False_Northing\",1200000.0],PARAMETER[\"Scale_Factor\",1.0],PARAMETER[\"Azimuth\",90.0],PARAMETER[\"Longitude_Of_Center\",7.439583333333333],PARAMETER[\"Latitude_Of_Center\",46.95240555555556],UNIT[\"Meter\",1.0]]'\n",
    "                )\n",
    "\n",
    "                # Print progress or other relevant information\n",
    "                print(f\"Processed: {file_path} -> {output_file_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"Switzerland_pr\", \"Switzerland_tasmax\", \"Switzerland_tasmin\", \"Switzerland_fst\", \"Switzerland_rsds\", \"Switzerland_vpd\"]\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(env.workspace, \"3PG\", folder)\n",
    "\n",
    "    # Get the list of .flt files in the folder and extract the year from each file name\n",
    "    file_list = [(file, re.search(r\"\\d{4}\", file).group()) for file in os.listdir(folder_path) if file.endswith('.flt')]\n",
    "\n",
    "    # Group the file paths by year\n",
    "    file_paths_by_year = {}\n",
    "    for file, year in file_list:\n",
    "        if year in file_paths_by_year:\n",
    "            file_paths_by_year[year].append(os.path.join(folder_path, file))\n",
    "        else:\n",
    "            file_paths_by_year[year] = [os.path.join(folder_path, file)]\n",
    "\n",
    "    # Write the file paths to a text file with the folder name\n",
    "    output_file = os.path.join(env.workspace, \"3PG\", f'{folder}.txt')\n",
    "    with open(output_file, 'w') as f:\n",
    "        for year, file_paths in file_paths_by_year.items():\n",
    "            # Write the year\n",
    "            f.write(f'{year} ')\n",
    "            f.write('     '.join(file_paths))\n",
    "            f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(env.workspace, \"3PG\", folder)\n",
    "\n",
    "    # Get the list of files in the directory using os.scandir()\n",
    "    with os.scandir(folder_path) as entries:\n",
    "        # Filter out directories and get only file names\n",
    "        file_names = [entry.name for entry in entries if entry.is_file()]\n",
    "        # Filter the list to only include .tif files\n",
    "        file_names = [f for f in file_names if f.endswith('.hdr')]\n",
    "\n",
    "    # Define the regular expression pattern to extract the date from the filename\n",
    "    pattern = r'^NODATA\\b(?!_value).*\\n'\n",
    "\n",
    "    # Iterate over the files in the directory\n",
    "    for file_name in file_names:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # Remove lines matching the pattern\n",
    "            modified_lines = [line for line in lines if not re.match(pattern, line)]\n",
    "\n",
    "            # Write the modified lines back to the file\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(modified_lines)\n",
    "\n",
    "            # Print progress or other relevant information\n",
    "            print(f\"Processed {file_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
